From 8bdd82b1ea7146c90851dc594b07b8857e788544 Mon Sep 17 00:00:00 2001
From: Ajaya Dahal <ajayad@amd.com>
Date: Wed, 19 Mar 2025 16:31:30 -0700
Subject: [PATCH] 3-lane-patch-mrmac

---
 drivers/net/ethernet/xilinx/xilinx_axienet.h  |   9 ++
 .../net/ethernet/xilinx/xilinx_axienet_main.c | 133 +++++++++++++++---
 2 files changed, 126 insertions(+), 16 deletions(-)

diff --git a/drivers/net/ethernet/xilinx/xilinx_axienet.h b/drivers/net/ethernet/xilinx/xilinx_axienet.h
index 834b05beaafe..dd64372c9fda 100644
--- a/drivers/net/ethernet/xilinx/xilinx_axienet.h
+++ b/drivers/net/ethernet/xilinx/xilinx_axienet.h
@@ -83,6 +83,10 @@
 				 XAE_OPTION_FLOW_CONTROL | \
 				 XAE_OPTION_RXEN)
 
+#define DELAY_OF_ONE_SEC		1000000
+#define MUX_10G_MASK 			0xF
+#define MUX_25G_MASK 			0x0
+
 /* Axi DMA Register definitions */
 
 #define XAXIDMA_TX_CR_OFFSET	0x00000000 /* Channel control */
@@ -636,6 +640,8 @@
 #define MRMAC_GT_RATE_OFFSET		0x0
 #define MRMAC_GT_CTRL_OFFSET		0x8
 
+#define MRMAC_GT_PLL_DONE_LANE_0_1_2_MASK	0x77
+
 #define MRMAC_GT_PLL_RST_MASK		0x00030003
 #define MRMAC_GT_PLL_DONE_MASK		0xFF
 #define MRMAC_GT_RST_ALL_MASK		BIT(0)
@@ -775,6 +781,7 @@ struct axidma_bd {
  * @tx_skb:	  Transmit skb address
  * @tx_desc_mapping: Tx Descriptor DMA mapping type.
  * @page:	page buffer to access the data passed by GRO packet
+ * @axi_mux: Mux is used for speed switching
  */
 struct aximcdma_bd {
 	phys_addr_t next;	/* Physical address of next buffer descriptor */
@@ -919,6 +926,8 @@ struct axienet_local {
 	void __iomem *regs;
 	void __iomem *mcdma_regs;
 
+	void __iomem *axi_mux;  /* mux is used for speed switching */
+
 	struct tasklet_struct dma_err_tasklet[XAE_MAX_QUEUES];
 	struct napi_struct napi[XAE_MAX_QUEUES];	/* NAPI Structure */
 
diff --git a/drivers/net/ethernet/xilinx/xilinx_axienet_main.c b/drivers/net/ethernet/xilinx/xilinx_axienet_main.c
index 85b5731f9d56..7b9f16c540a0 100644
--- a/drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ b/drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -91,12 +91,34 @@ EXPORT_SYMBOL(mrmac_gt_pll);
 void __iomem *mrmac_gt_ctrl;
 EXPORT_SYMBOL(mrmac_gt_ctrl);
 
+void __iomem *axi_mux_gpio;
+EXPORT_SYMBOL(axi_mux_gpio);
+
 int mrmac_pll_reg;
 EXPORT_SYMBOL(mrmac_pll_reg);
 
 int mrmac_pll_rst;
 EXPORT_SYMBOL(mrmac_pll_rst);
 
+int axi_mux_reg;
+EXPORT_SYMBOL(axi_mux_reg);
+
+static inline void axienet_reset_mux(struct axienet_local *lp)
+{
+	u32 val;
+
+	val = ioread32(lp->axi_mux);
+
+	if (lp->max_speed == SPEED_25000) {
+		val &= ~(1 << lp->gt_lane);
+		iowrite32(val, lp->axi_mux);
+	} else {
+		val |= 1 << lp->gt_lane;
+		iowrite32(val, lp->axi_mux);
+	}
+}
+
+
 /* Option table for setting up Axi Ethernet hardware options */
 static struct axienet_option axienet_options[] = {
 	/* Turn on jumbo packet support for both Rx and Tx */
@@ -733,18 +755,23 @@ static inline int axienet_mrmac_gt_reset(struct net_device *ndev)
 
 	if (mrmac_pll_rst == 0) {
 		for (i = 0; i < MRMAC_MAX_GT_LANES; i++) {
-			iowrite32(MRMAC_GT_RST_ALL_MASK, (lp->gt_ctrl +
-				  (MRMAC_GT_LANE_OFFSET * i) +
-				  MRMAC_GT_CTRL_OFFSET));
-			mdelay(DELAY_1MS);
-			iowrite32(0, (lp->gt_ctrl + (MRMAC_GT_LANE_OFFSET * i) +
-				      MRMAC_GT_CTRL_OFFSET));
+			if((i==0) || (i==2)){
+				iowrite32(MRMAC_GT_RST_ALL_MASK, (lp->gt_ctrl +
+					(MRMAC_GT_LANE_OFFSET * i) +
+					MRMAC_GT_CTRL_OFFSET));
+				
+				
+				mdelay(DELAY_1MS*300);
+				iowrite32(0, (lp->gt_ctrl + (MRMAC_GT_LANE_OFFSET * i) +
+						MRMAC_GT_CTRL_OFFSET));
+				//break;
+			}
 		}
 
 		/* Wait for PLL lock with timeout */
 		err = readl_poll_timeout(lp->gt_pll + MRMAC_GT_PLL_STS_OFFSET,
-					 val, (val & MRMAC_GT_PLL_DONE_MASK),
-					 10, DELAY_OF_ONE_MILLISEC);
+					 val, ((val & MRMAC_GT_PLL_DONE_LANE_0_1_2_MASK) == MRMAC_GT_PLL_DONE_LANE_0_1_2_MASK),
+					 10, DELAY_OF_ONE_MILLISEC*1000);
 		if (err) {
 			netdev_err(ndev, "MRMAC PLL lock not complete! Cross-check the MAC ref clock configuration\n");
 			return -ENODEV;
@@ -760,6 +787,7 @@ static inline int axienet_mrmac_gt_reset(struct net_device *ndev)
 		iowrite32(MRMAC_GT_10G_MASK, (lp->gt_ctrl +
 			  MRMAC_GT_LANE_OFFSET * lp->gt_lane +
 			  MRMAC_GT_RATE_OFFSET));
+	
 
 	iowrite32(MRMAC_GT_RST_RX_MASK | MRMAC_GT_RST_TX_MASK,
 		  (lp->gt_ctrl + MRMAC_GT_LANE_OFFSET * lp->gt_lane +
@@ -768,7 +796,6 @@ static inline int axienet_mrmac_gt_reset(struct net_device *ndev)
 	iowrite32(0, (lp->gt_ctrl + MRMAC_GT_LANE_OFFSET * lp->gt_lane +
 		  MRMAC_GT_CTRL_OFFSET));
 	mdelay(DELAY_1MS);
-
 	return 0;
 }
 
@@ -839,6 +866,8 @@ static int axienet_device_reset(struct net_device *ndev)
 
 	if (lp->axienet_config->mactype == XAXIENET_MRMAC) {
 		/* Reset MRMAC */
+		if (axi_mux_reg)
+			axienet_reset_mux(lp);
 		axienet_mrmac_reset(lp);
 	}
 
@@ -1149,6 +1178,7 @@ static void axienet_rx_hwtstamp(struct axienet_local *lp,
 }
 #endif
 
+
 /**
  * axienet_start_xmit_done - Invoked once a transmit is completed by the
  * Axi DMA Tx channel.
@@ -2214,19 +2244,18 @@ static int axienet_open(struct net_device *ndev)
 		/* Reset MRMAC */
 		axienet_mrmac_reset(lp);
 
-		mdelay(DELAY_1MS);
+		mdelay(DELAY_1MS*100);
 		/* Check for block lock bit to be set. This ensures that
 		 * MRMAC ethernet IP is functioning normally.
 		 */
 		axienet_iow(lp, MRMAC_TX_STS_OFFSET, MRMAC_STS_ALL_MASK);
 		axienet_iow(lp, MRMAC_RX_STS_OFFSET, MRMAC_STS_ALL_MASK);
 		err = readx_poll_timeout(axienet_get_mrmac_blocklock, lp, val,
-					 (val & MRMAC_RX_BLKLCK_MASK), 10, DELAY_OF_ONE_MILLISEC);
+					 (val & MRMAC_RX_BLKLCK_MASK), 10, DELAY_OF_ONE_MILLISEC*1000);
 		if (err)
 			netdev_err(ndev, "MRMAC block lock not complete! Cross-check the MAC ref clock configuration\n");
-
 		err = readx_poll_timeout(axienet_get_mrmac_rx_status, lp, val,
-					 (val & MRMAC_RX_STATUS_MASK), 10, DELAY_OF_ONE_MILLISEC);
+					 (val & MRMAC_RX_STATUS_MASK), 10, DELAY_OF_ONE_MILLISEC*1000);
 		if (err) {
 			netdev_err(ndev, "MRMAC Link is down!\n");
 			ret = -ENODEV;
@@ -2235,10 +2264,10 @@ static int axienet_open(struct net_device *ndev)
 
 		axienet_iow(lp, MRMAC_STATRX_VALID_CTRL_OFFSET, MRMAC_STS_ALL_MASK);
 		val = axienet_ior(lp, MRMAC_STATRX_VALID_CTRL_OFFSET);
-
 		if (!(val & MRMAC_RX_VALID_MASK)) {
 			netdev_err(ndev, "MRMAC Link is down! No recent RX Valid Control Code\n");
 			ret = -ENODEV;
+
 			goto err_eth_irq;
 		}
 		netdev_info(ndev, "MRMAC setup at %d\n", lp->max_speed);
@@ -2811,7 +2840,12 @@ axienet_ethtools_get_coalesce(struct net_device *ndev,
 	for_each_rx_dma_queue(lp, i) {
 		q = lp->dq[i];
 
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+		regval = axienet_dma_in32(q, XMCDMA_CHAN_CR_OFFSET(q->chan_id) +
+				      XMCDMA_RX_OFFSET);
+#else
 		regval = axienet_dma_in32(q, XAXIDMA_RX_CR_OFFSET);
+#endif
 		ecoalesce->rx_max_coalesced_frames +=
 						(regval & XAXIDMA_COALESCE_MASK)
 						     >> XAXIDMA_COALESCE_SHIFT;
@@ -2819,7 +2853,11 @@ axienet_ethtools_get_coalesce(struct net_device *ndev,
 	}
 	for_each_tx_dma_queue(lp, i) {
 		q = lp->dq[i];
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+		regval = axienet_dma_in32(q, XMCDMA_CHAN_CR_OFFSET(q->chan_id));
+#else
 		regval = axienet_dma_in32(q, XAXIDMA_TX_CR_OFFSET);
+#endif
 		ecoalesce->tx_max_coalesced_frames +=
 						(regval & XAXIDMA_COALESCE_MASK)
 						     >> XAXIDMA_COALESCE_SHIFT;
@@ -3006,6 +3044,35 @@ static void axienet_ethtools_get_stats(struct net_device *ndev,
  *
  * Return: None.
  */
+
+static int axienet_change_speed(struct net_device *dev, const struct ethtool_link_ksettings *cmd)
+{
+	struct axienet_local *lp = netdev_priv(dev);
+	int ret = 0;
+
+	if (lp->axienet_config->mactype == XAXIENET_MRMAC) {
+		lp->max_speed = cmd->base.speed;
+		return 0;
+	} else {
+
+		return phy_ethtool_set_link_ksettings(dev, cmd);
+	}
+}
+
+static int axienet_get_speed(struct net_device *dev,  struct ethtool_link_ksettings *cmd)
+{
+	struct axienet_local *lp = netdev_priv(dev);
+
+	if (lp->axienet_config->mactype == XAXIENET_MRMAC) {
+		cmd->base.speed = lp->max_speed;
+		return 0;
+	} else {
+
+		return phy_ethtool_get_link_ksettings(dev, cmd);
+	}
+}
+
+ 
 static void axienet_ethtools_strings(struct net_device *ndev, u32 sset, u8 *data)
 {
 	int i;
@@ -3099,8 +3166,8 @@ static const struct ethtool_ops axienet_ethtool_ops = {
 	.get_sset_count	= axienet_ethtools_sset_count,
 	.get_ethtool_stats = axienet_ethtools_get_stats,
 	.get_strings = axienet_ethtools_strings,
-	.get_link_ksettings = axienet_ethtools_get_link_ksettings,
-	.set_link_ksettings = axienet_ethtools_set_link_ksettings,
+	.get_link_ksettings = axienet_get_speed,
+	.set_link_ksettings = axienet_change_speed,
 	.nway_reset	= axienet_ethtools_nway_reset,
 #ifdef CONFIG_XILINX_AXI_EOE
 	.get_rxnfc = axienet_eoe_get_rxnfc,
@@ -3992,6 +4059,7 @@ static int axienet_probe(struct platform_device *pdev)
 	struct resource txtsres, rxtsres;
 #endif
 	u16 num_queues = XAE_MAX_QUEUES;
+	struct resource axi_mux;
 
 	ret = of_property_read_u16(pdev->dev.of_node, "xlnx,num-queues",
 				   &num_queues);
@@ -4274,6 +4342,39 @@ static int axienet_probe(struct platform_device *pdev)
 			goto cleanup_clk;
 		}
 		dev_info(&pdev->dev, "GT lane: %d\n", lp->gt_lane);
+
+		if(axi_mux_reg) {
+				lp->axi_mux = axi_mux_gpio;
+				dev_info(&pdev->dev, "AXI MUX REG: %d\n", lp->axi_mux);
+		} else {
+			np = of_parse_phandle(pdev->dev.of_node,
+					"xlnx,axi_mux", 0);
+			if (IS_ERR(np)) {
+				dev_warn(&pdev->dev,
+						"couldn't find axi_mux switching not supported\n");
+			} else {
+
+				ret = of_address_to_resource(np, 0, &axi_mux);
+				dev_info(&pdev->dev, "AXI MUX from DT: %x\n\n", &axi_mux);
+				if (ret) {
+					dev_warn(&pdev->dev,
+							"unable to get axi_mux resource\n");
+				}
+
+				lp->axi_mux = devm_ioremap_resource(&pdev->dev,
+						&axi_mux);
+				if (IS_ERR(lp->axi_mux)) {
+					dev_warn(&pdev->dev,
+							"couldn't map axi_mux regs\n");
+				} else {
+					axi_mux_gpio = lp->axi_mux;
+					axi_mux_reg = 1;
+				}
+			}
+
+		}
+			
+
 	} else if (lp->axienet_config->mactype == XAXIENET_DCMAC) {
 		lp->gds_gt_ctrl = devm_gpiod_get_array(&pdev->dev,
 						       "gt_ctrl",
-- 
2.25.1

